{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "A Neural Network is a predictive model motivated by the way the human brain works.\n",
    "\n",
    "Input, Hidden and Output laysers\n",
    "\n",
    "Artifitial Neural Networks consists of artifitial neurons, that develop similar calculus\n",
    "about your entries.\n",
    "\n",
    "This kind of structure is very useful for Data Scientists, because they can solve a big\n",
    "variety of problems like handwriting and facial recognition among others.\n",
    "\n",
    "Data Scientists are very fond of using there resources of Neural Networks.\n",
    "Is is one of the most used resources.\n",
    "\n",
    "In addition to the intelligence that may be behind learning from the artificial neural\n",
    "network, other devices such as Bayesian logic, Fuzzy logic, and the combination of\n",
    "joint logic such as neuro-fuzzy can also be used. That is one of the intelligence\n",
    "logics behind the newer devices that are emerging in terms of learning and decision making.\n",
    "\n",
    "However, because our study is based on decision tree and neural networks,\n",
    "we will focus today on neural networks.\n",
    "\n",
    "* Perceptron\n",
    "* Artifitial Neural Network\n",
    "* Feed Forward\n",
    "* Back Propagation\n",
    "\n",
    "\n",
    "* Convolutional Neural Network\n",
    "* Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks - Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPERVIZED LEARNING WITH ARTIFICIAL NEURAL NETWORKS - Perceptrons\n",
      "\n",
      "Training...\n",
      " \n",
      "INTERACTION 1-------------------------\n",
      "dog = pattern not identified = Fail - Wheight updated\n",
      "cat = pattern not identified = Fail - Wheight updated\n",
      "horse = quadruped = hit\n",
      "men = quadruped = Fail - Wheight updated\n",
      "\n",
      "INTERACTION 2-------------------------\n",
      "dog = quadruped = hit\n",
      "cat = quadruped = hit\n",
      "horse = pattern not identified = Fail - Wheight updated\n",
      "men = biped = hit\n",
      "\n",
      "INTERACTION 3-------------------------\n",
      "dog = quadruped = hit\n",
      "cat = quadruped = hit\n",
      "horse = quadruped = hit\n",
      "men = biped = hit\n",
      "\n",
      "Functionality learned with 3 interactions\n",
      "\n",
      "Finished successfully\n"
     ]
    }
   ],
   "source": [
    "# script to verify if the living being is quadruped or biped\n",
    "\n",
    "# quadruped = 1, biped = -1\n",
    "\n",
    "# dog = [-1,-1,1,1] | answer = 1\n",
    "# cat = [1,1,1,1] | answer = 1\n",
    "# horse = [1,1,-1,1] | answer = 1\n",
    "# men = [-1,-1,-1,1] | answer = -1\n",
    "\n",
    "\n",
    "# wheights (sinapses)\n",
    "w = [0,0,0,0]\n",
    "\n",
    "# inputs\n",
    "x = [[-1,-1,1,1],\n",
    "[1,1,1,1],\n",
    "[1,1,-1,1],\n",
    "[-1,-1,-1,1]]\n",
    "\n",
    "# expected responses\n",
    "t = [1,1,1,-1]\n",
    "\n",
    "# bias (fine adjustment)\n",
    "b = 0\n",
    "\n",
    "# output\n",
    "y = 0\n",
    "\n",
    "# max number of interactions\n",
    "max_int = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 1\n",
    "\n",
    "# total\n",
    "soma = 0\n",
    "\n",
    "# threshold\n",
    "threshold = 1\n",
    "\n",
    "# animal's name\n",
    "animal = \"\"\n",
    "\n",
    "# answer = hit or miss\n",
    "answer = \"\"\n",
    "\n",
    "# data dictionary\n",
    "d = {'-1,-1,1,1' : 'dog',\n",
    "'1,1,1,1' : 'cat',\n",
    "'1,1,-1,1' : 'horse',\n",
    "'-1,-1,-1,1' : 'men' }\n",
    "\n",
    "print(\"SUPERVIZED LEARNING WITH ARTIFICIAL NEURAL NETWORKS - Perceptrons\")\n",
    "print(\"\\nTraining...\")\n",
    "print(\" \")\n",
    "\n",
    "# function to convert lists into strings\n",
    "def listToString(list):\n",
    "    s = str(list).strip('[]')\n",
    "    s = s.replace(' ', '')\n",
    "    return s\n",
    "\n",
    "\n",
    "# beginning of the algorithm\n",
    "for k in range(1,max_int):\n",
    "    hits = 0\n",
    "    print(\"INTERACTION \"+str(k)+\"-------------------------\")\n",
    "    for i in range(0,len(x)):\n",
    "        soma = 0\n",
    "        # takes the animal name from dictionary\n",
    "        if d.has_key(listToString(x[i])):\n",
    "            animal = d[listToString(x[i])]\n",
    "        else:\n",
    "            animal = \"\"\n",
    "        # to calculate the perceptron's output, each x input is multiplied\n",
    "        # by it's corresponding wheight w\n",
    "        for j in range(0,len(x[i])):\n",
    "            soma += x[i][j] * w[j]\n",
    "        # the output is equal to the addition of the bias with the previous sum\n",
    "        y_in = b + soma\n",
    "        #print(\"y_in = \",str(y_in))\n",
    "\n",
    "        # output function is determined by the threshold\n",
    "        if y_in > threshold:\n",
    "            y = 1\n",
    "        elif y_in >= -threshold and y_in <= threshold:\n",
    "            y = 0\n",
    "        else:\n",
    "            y = -1\n",
    "        # update the weights if the output does not match the expected value\n",
    "        if y == t[i]:\n",
    "            hits+=1\n",
    "            answer = \"hit\"\n",
    "        else:\n",
    "            for j in range (0,len(w)):\n",
    "                w[j] = w[j] + (learning_rate * t[i] * x[i][j])\n",
    "            b = b + learning_rate * t[i]\n",
    "            answer = \"Fail - Wheight updated\"\n",
    "        # prints the answer\n",
    "        if y == 1:\n",
    "            print(animal+\" = quadruped = \"+answer)\n",
    "        elif y == 0:\n",
    "            print(animal+\" = pattern not identified = \"+answer)\n",
    "        elif y == -1:\n",
    "            print(animal+\" = biped = \"+answer)\n",
    "    if hits == len(x):\n",
    "        print(\"\\nFunctionality learned with \"+str(k)+\" interactions\")\n",
    "        break;\n",
    "    print(\"\")\n",
    "print(\"\\nFinished successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks - Feed-Forward\n",
    "\n",
    "Since the brain topology is too complicated, it can be aproximated as an idealized **feed-forward**, which consists of discrete layers of neurons, each layer connected to the next one.\n",
    "Like the **perceptron**, the products of it's inputs must be added with it's respective weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# script to analyze OR gates\n",
    "# false = 0, true = 1\n",
    "\n",
    "# [0,0] | answer = 0\n",
    "# [0,1] | answer = 1\n",
    "# [1,0] | answer = 1\n",
    "# [1,1] | answer = 1\n",
    "\n",
    "# max number of interactions\n",
    "max_int = 20\n",
    "\n",
    "# threshold (limiar)\n",
    "threshold = 0\n",
    "\n",
    "# wheight 0\n",
    "w_0 = -threshold\n",
    "\n",
    "# input 0\n",
    "x_0 = 1\n",
    "\n",
    "# inputs\n",
    "x = [[x_0,0,0],\n",
    "[x_0,0,1],\n",
    "[x_0,1,0],\n",
    "[x_0,1,1]]\n",
    "\n",
    "# how many items has vector x (4)\n",
    "size_x = len(x)\n",
    "\n",
    "# how many items are in each position of vector x\n",
    "qtd_items_x = len(x[0])\n",
    "\n",
    "# wheights (sinapses)\n",
    "w = [w_0,0,0]\n",
    "\n",
    "# how many items has the vector w (3)\n",
    "size_w = len(w)\n",
    "\n",
    "# desired answers\n",
    "d = [0,1,1,1]\n",
    "\n",
    "# learning rate (n)\n",
    "learning_rate = 0.5\n",
    "\n",
    "# output\n",
    "y = 0\n",
    "\n",
    "\n",
    "# answers = hit or fail\n",
    "answer = \"\"\n",
    "\n",
    "# soma\n",
    "u = 0\n",
    "\n",
    "# error\n",
    "e = 0\n",
    "\n",
    "print(\"SUPERVIZED LEARNING WITH ARTIFICIAL NEURAL NETWORKS - Feed-Forward\\n\")\n",
    "\n",
    "# beginning of the algorithm\n",
    "for k in range(1,max_int):\n",
    "    hits = 0\n",
    "    e = 0\n",
    "    print(\"INTERACTION \"+str(k)+\"-------------------------\")\n",
    "    for t in range(0,size_x):\n",
    "        u = 0\n",
    "        \n",
    "        # to calculate the output of the perceptron, each input of x is multiplied\n",
    "        # by it's corresponding weight w\n",
    "        for j in range(0,qtd_items_x):\n",
    "            u += x[t][j] * w[j]\n",
    "\n",
    "        # output function\n",
    "        if u > 0:\n",
    "            y = 1\n",
    "        else:\n",
    "            y = 0\n",
    "        \n",
    "        # updates the weights if the output does not corresponds to expected value\n",
    "        if y == d[t]:\n",
    "            answer = \"hit\"\n",
    "            hits += 1\n",
    "            e = 0\n",
    "        else:\n",
    "            answer = \"error\"\n",
    "            \n",
    "            # computing the error\n",
    "            e = d[t] - y\n",
    "            \n",
    "            # updating the weights\n",
    "            for j in range(0, size_w):\n",
    "                w[j] = w[j] + (learning_rate * e * x[t][j])\n",
    "        \n",
    "        print(answer + \" >>> u = \" + \", y = \" + str(y) + \", e = \" + str(e))\n",
    "        \n",
    "    if hits == size_x:\n",
    "        print(\"\\nFunctionality learned with \" + str(k) + \" interactions\")\n",
    "        print(\"\\nWeights found===============\")\n",
    "        for j in range(0,size_w):\n",
    "            print(w[j])\n",
    "        break;\n",
    "    print(\"\")\n",
    "print(\"Finalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks - Backpropagation\n",
    "\n",
    "One of the options of artificial neural networks is to work with the famous backpropagation algorithm, whose main advantages are to work with multilayers and solve \"non-linearly separable\" problems that some algorithms do not solve.\n",
    "\n",
    "A \"non-linearly separable\" problem is one in which we can not separate two distinct classes on the two-dimensional Cartesian axis by just drawing a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"SUPERVIZED LEARNING WITH ARTIFICIAL NEURAL NETWORKS - BACKPROPAGATION\\n\")\n",
    "\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, NI, NH, NO):\n",
    "        # number of nodes in layers\n",
    "        self.ni = NI + 1 # +1 for bias\n",
    "        self.nh = NH\n",
    "        self.no = NO\n",
    "        \n",
    "        # initialize node-activations\n",
    "        self.ai, self.ah, self.ao = [],[],[] # blank lists\n",
    "        self.ai = [1.0] * self.ni\n",
    "        self.ah = [1.0] * self.nh\n",
    "        self.ao = [1.0] * self.no\n",
    "        \n",
    "        # create node weight matrices\n",
    "        self.wi = makeMatrix(self.ni, self.nh)\n",
    "        self.wo = makeMatrix(self.nh, self.no)\n",
    "        \n",
    "        # initialize node weights to random vals\n",
    "        randomizeMatrix(self.wi, -0.2, 0.2)\n",
    "        randomizeMatrix(self.wo, -2.0, 2.0)\n",
    "        \n",
    "        # create last change in weights matrices for momentum\n",
    "        self.ci = makeMatrix(self.ni, self.nh)\n",
    "        self.co = makeMatrix(self.nh, self.no)\n",
    "    \n",
    "    def runNN(self, inputs):\n",
    "        if len(inputs) != self.ni -1:\n",
    "            print 'incorrect number of inputs'\n",
    "        \n",
    "        for i in range(self.ni -1):\n",
    "            self.ai[i] = inputs[i]\n",
    "        \n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum += (self.ai[i] * self.wi[i][j])\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "        \n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum += (self.ah[j] * self.wo[j][k])\n",
    "            self.ao[k] = sigmoid (sum)\n",
    "        \n",
    "        return self.ao\n",
    "    \n",
    "    def backPropagate(self, targets, N, M):\n",
    "        # calc output deltas\n",
    "        output_deltas = [0.0] * self.no\n",
    "        \n",
    "        for k in range(self.no):\n",
    "            error = targets[k] - self.ao[k]\n",
    "            output_deltas[k] = error * dsigmoid(self.ao[k])\n",
    "        \n",
    "        # update output weights\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                # output_deltas[k] * self.ah[j] is the full derivative of dError/dweight[j][k]\n",
    "                change = output_deltas[k] * self.ah[j]\n",
    "                self.wo[j][k] += N * change + M * self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    "        \n",
    "        # calc hidden deltas\n",
    "        hidden_deltas = [0.0] * self.nh\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error += output_deltas[k] * self.wo[j][k]\n",
    "            hidden_deltas[j] = error * dsigmoid(self.ah[j])\n",
    "        \n",
    "        # update input weights\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j] * self.ai[i]\n",
    "                # print 'activation', self.ai[i], 'synapse', i, j, 'change',change\n",
    "                self.wi[i][j] += N * change + M * self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    "        \n",
    "        # calc combined error\n",
    "        # 1/2 for differential convenience & **2 for modulus\n",
    "        error = 0.0\n",
    "        \n",
    "        for k in range(len(targets)):\n",
    "            error = 0.5 * (targets[k] - self.ao[k])**2\n",
    "        return error\n",
    "    \n",
    "    def weights(self):\n",
    "        print 'Input weights:'\n",
    "        for i in range(self.ni):\n",
    "            print self.wi[i]\n",
    "            \n",
    "        print\n",
    "        print 'Output weights:'\n",
    "        for j in range(self.nh):\n",
    "            print self.wo[j]\n",
    "        print ''\n",
    "    \n",
    "    def test(self, patterns):\n",
    "        for p in patterns:\n",
    "            inputs = p[0]\n",
    "            print 'Inputs:', p[0], '-->', self.runNN(inputs), '\\tTarget', p[1]\n",
    "    \n",
    "    def train(self, patterns, max_iterations = 1000, N = 0.5, M = 0.1):\n",
    "        for i in range(max_iterations):\n",
    "            for p in patterns:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.runNN(inputs)\n",
    "                error = self.backPropagate(targets, N, M)\n",
    "            if i % 50 == 0:\n",
    "                print 'Combined error', error\n",
    "        self.test(patterns)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "# the derivative of the sigmoid function in terms of ouput\n",
    "# proff here:\n",
    "# http://www.math10.com/en/algebra/hyperbolic-function/hyperbolic-function.html\n",
    "def dsigmoid(y):\n",
    "    return 1 - y**2\n",
    "\n",
    "def makeMatrix(I, J, fill=0.0):\n",
    "    m = []\n",
    "    for i in range(I):\n",
    "        m.append([fill] * J)\n",
    "    return m\n",
    "\n",
    "def randomizeMatrix(matrix, a, b):\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[0])):\n",
    "            matrix[i][j] = random.uniform(a,b)\n",
    "\n",
    "def main():\n",
    "    pat = [\n",
    "        [[0,0],[1]],\n",
    "        [[0,1],[1]],\n",
    "        [[1,0],[1]],\n",
    "        [[1,1],[0]]\n",
    "    ]\n",
    "\n",
    "    myNN = NN( 2, 2, 1)\n",
    "    myNN.train(pat)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
